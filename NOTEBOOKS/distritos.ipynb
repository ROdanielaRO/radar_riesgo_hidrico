{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3fdbd5",
   "metadata": {},
   "source": [
    "#Análisis de Datos Geoespaciales - Centros Poblados (CCPP)\n",
    "\n",
    "Este notebook está diseñado para **extraer, explorar y visualizar** los datos geoespaciales contenidos en la carpeta `CCPP_0`.\n",
    "\n",
    "##  **Tipos de Archivos Detectados:**\n",
    "\n",
    "Los archivos en tu carpeta `CCPP_0` son **Shapefiles**, un formato estándar para datos vectoriales geoespaciales:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21beb7a0",
   "metadata": {},
   "source": [
    "## 📊 CARGA Y EXPLORACIÓN DE DATOS SHAPEFILE\n",
    "\n",
    "Ahora que tenemos el entorno configurado, vamos a cargar y explorar los datos de Centros Poblados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae770326",
   "metadata": {},
   "source": [
    "## 📋 EXPLORACIÓN DE ATRIBUTOS Y COORDENADAS\n",
    "\n",
    "Los archivos Shapefile contienen **AMBOS**: datos tabulares (columnas) Y geometrías (coordenadas). Vamos a explorar qué información contienen usando métodos alternativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0758a968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 EXPLORANDO ATRIBUTOS Y COORDENADAS DEL SHAPEFILE\n",
      "============================================================\n",
      "📋 MÉTODO 1: Explorando archivo .DBF (datos tabulares)\n",
      "--------------------------------------------------\n",
      "🔄 Intentando encoding: utf-8\n",
      "✅ DBF Header leído exitosamente!\n",
      "   📊 Número de registros: 136,587\n",
      "   📏 Longitud de registro: 418 bytes\n",
      "   📅 Fecha de modificación: 24/9/2018\n",
      "   📋 Número de campos/columnas: 13\n",
      "\n",
      "📝 COLUMNAS DETECTADAS:\n",
      "    1. OBJECTID     | Tipo: N | Longitud: 10\n",
      "    2. NOM_POBLAD   | Tipo: C | Longitud: 60\n",
      "    3. FUENTE       | Tipo: C | Longitud: 5\n",
      "    4. CÓDIGO       | Tipo: C | Longitud: 10\n",
      "    5. CAT_POBLAD   | Tipo: C | Longitud: 25\n",
      "    6. DIST         | Tipo: C | Longitud: 60\n",
      "    7. PROV         | Tipo: C | Longitud: 50\n",
      "    8. DEP          | Tipo: C | Longitud: 50\n",
      "    9. CÓD_INT      | Tipo: C | Longitud: 4\n",
      "   10. CATEGORIA    | Tipo: C | Longitud: 25\n",
      "   11. X            | Tipo: N | Longitud: 19\n",
      "   12. Y            | Tipo: N | Longitud: 19\n",
      "   13. N_BUSQDA     | Tipo: C | Longitud: 80\n",
      "\n",
      "🎯 RESUMEN DE CONTENIDO:\n",
      "   • El shapefile contiene 136,587 centros poblados\n",
      "   • Cada centro poblado tiene 13 atributos/columnas\n",
      "   • Además de coordenadas geográficas (geometría)\n",
      "\n",
      "💡 EXPLICACIÓN:\n",
      "   🗂️  Los archivos Shapefile son HÍBRIDOS:\n",
      "       📊 Datos tabulares (como CSV) = atributos de cada lugar\n",
      "       🗺️  Datos geoespaciales = coordenadas y geometrías\n",
      "   📍 Cada fila representa un centro poblado CON:\n",
      "       📝 Atributos (nombre, código, población, etc.)\n",
      "       🌍 Coordenadas geográficas (latitud, longitud)\n"
     ]
    }
   ],
   "source": [
    "# 🔍 EXPLORAR ATRIBUTOS USANDO ARCHIVO .DBF\n",
    "print(\"🔍 EXPLORANDO ATRIBUTOS Y COORDENADAS DEL SHAPEFILE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# Vamos a leer el archivo .dbf que contiene los atributos\n",
    "DBF_PATH = '../CCPP_0/CCPP_IGN100K.dbf'\n",
    "\n",
    "print(\"📋 MÉTODO 1: Explorando archivo .DBF (datos tabulares)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # Intentar con pandas y diferentes encoding\n",
    "    encodings_to_try = ['utf-8', 'latin1', 'cp1252', 'iso-8859-1']\n",
    "    \n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            # Usando pandas para leer DBF como archivo binario\n",
    "            print(f\"🔄 Intentando encoding: {encoding}\")\n",
    "            \n",
    "            # Método alternativo: usar struct para leer DBF\n",
    "            import struct\n",
    "            \n",
    "            with open(DBF_PATH, 'rb') as f:\n",
    "                # Leer header del DBF\n",
    "                header = f.read(32)\n",
    "                if len(header) >= 32:\n",
    "                    # Extraer información del header\n",
    "                    version = header[0]\n",
    "                    year = header[1] + 1900 if header[1] > 0 else 2000 + header[1]\n",
    "                    month = header[2]\n",
    "                    day = header[3]\n",
    "                    num_records = struct.unpack('<L', header[4:8])[0]\n",
    "                    header_length = struct.unpack('<H', header[8:10])[0]\n",
    "                    record_length = struct.unpack('<H', header[10:12])[0]\n",
    "                    \n",
    "                    print(f\"✅ DBF Header leído exitosamente!\")\n",
    "                    print(f\"   📊 Número de registros: {num_records:,}\")\n",
    "                    print(f\"   📏 Longitud de registro: {record_length} bytes\")\n",
    "                    print(f\"   📅 Fecha de modificación: {day}/{month}/{year}\")\n",
    "                    \n",
    "                    # Calcular número de campos\n",
    "                    num_fields = (header_length - 33) // 32\n",
    "                    print(f\"   📋 Número de campos/columnas: {num_fields}\")\n",
    "                    \n",
    "                    # Leer descriptores de campos\n",
    "                    print(f\"\\n📝 COLUMNAS DETECTADAS:\")\n",
    "                    fields = []\n",
    "                    for i in range(num_fields):\n",
    "                        field_desc = f.read(32)\n",
    "                        if len(field_desc) >= 32:\n",
    "                            field_name = field_desc[:11].decode('utf-8', errors='ignore').rstrip('\\x00')\n",
    "                            field_type = chr(field_desc[11])\n",
    "                            field_length = field_desc[16]\n",
    "                            field_decimal = field_desc[17]\n",
    "                            \n",
    "                            fields.append({\n",
    "                                'name': field_name,\n",
    "                                'type': field_type,\n",
    "                                'length': field_length,\n",
    "                                'decimal': field_decimal\n",
    "                            })\n",
    "                            \n",
    "                            print(f\"   {i+1:2d}. {field_name:<12} | Tipo: {field_type} | Longitud: {field_length}\")\n",
    "                    \n",
    "                    break  # Si llegamos aquí, fue exitoso\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error con {encoding}: {str(e)[:50]}...\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n🎯 RESUMEN DE CONTENIDO:\")\n",
    "    print(f\"   • El shapefile contiene {num_records:,} centros poblados\")\n",
    "    print(f\"   • Cada centro poblado tiene {num_fields} atributos/columnas\")\n",
    "    print(f\"   • Además de coordenadas geográficas (geometría)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error general: {e}\")\n",
    "    print(\"🔧 Intentando método alternativo...\")\n",
    "\n",
    "print(f\"\\n💡 EXPLICACIÓN:\")\n",
    "print(f\"   🗂️  Los archivos Shapefile son HÍBRIDOS:\")\n",
    "print(f\"       📊 Datos tabulares (como CSV) = atributos de cada lugar\")\n",
    "print(f\"       🗺️  Datos geoespaciales = coordenadas y geometrías\") \n",
    "print(f\"   📍 Cada fila representa un centro poblado CON:\")\n",
    "print(f\"       📝 Atributos (nombre, código, población, etc.)\")\n",
    "print(f\"       🌍 Coordenadas geográficas (latitud, longitud)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84fe9516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 EXTRAYENDO COORDENADAS Y DATOS DE LOS CENTROS POBLADOS\n",
      "======================================================================\n",
      "🔄 Extrayendo muestra de datos...\n",
      "📋 MUESTRA DE DATOS (primeros 5 registros):\n",
      "----------------------------------------------------------------------\n",
      "   1. ID: 1\n",
      "      📍 Nombre: PANDISHARI\n",
      "      🌍 Coordenada X: -74.06462000\n",
      "      🌍 Coordenada Y: -10.37129000\n",
      "\n",
      "   2. ID: 2\n",
      "      📍 Nombre: CHICOSA\n",
      "      🌍 Coordenada X: -74.06153000\n",
      "      🌍 Coordenada Y: -10.37852000\n",
      "\n",
      "   3. ID: 3\n",
      "      📍 Nombre: RAYA\n",
      "      🌍 Coordenada X: -72.94118000\n",
      "      🌍 Coordenada Y: -10.33043000\n",
      "\n",
      "   4. ID: 4\n",
      "      📍 Nombre: PENSILVANIA\n",
      "      🌍 Coordenada X: -74.05988000\n",
      "      🌍 Coordenada Y: -10.40401000\n",
      "\n",
      "   5. ID: 5\n",
      "      📍 Nombre: PONTE VEDRA\n",
      "      🌍 Coordenada X: -74.03788000\n",
      "      🌍 Coordenada Y: -10.41809000\n",
      "\n",
      "✅ Extracción de muestra completada!\n",
      "\n",
      "🗺️ INFORMACIÓN SOBRE LAS COORDENADAS:\n",
      "   📐 Las columnas X e Y contienen coordenadas geográficas\n",
      "   🌍 Estas coordenadas representan la ubicación exacta de cada centro poblado\n",
      "   📊 Hay 136,587 centros poblados con sus respectivas coordenadas\n",
      "\n",
      "📋 COLUMNAS DISPONIBLES PARA ANÁLISIS:\n",
      "   1. 📍 NOM_POBLAD - Nombre del centro poblado\n",
      "   2. 🏛️  DIST - Distrito\n",
      "   3. 🗺️  PROV - Provincia\n",
      "   4. 🏴 DEP - Departamento\n",
      "   5. 🏷️  CATEGORIA - Categoría del centro poblado\n",
      "   6. 🌍 X, Y - Coordenadas geográficas (CLAVE PARA TU ANÁLISIS)\n",
      "\n",
      "🎯 PARA TU ANÁLISIS DE RIESGO HÍDRICO:\n",
      "   • Puedes usar las coordenadas X, Y para ubicar geográficamente los centros poblados\n",
      "   • Cruzar con tus datos de monitoreo de agua usando proximidad geográfica\n",
      "   • Identificar qué centros poblados están cerca de zonas de alto riesgo\n",
      "   • Analizar por departamento, provincia o distrito\n"
     ]
    }
   ],
   "source": [
    "# 📊 EXTRAER COORDENADAS Y DATOS ESPECÍFICOS\n",
    "print(\"📊 EXTRAYENDO COORDENADAS Y DATOS DE LOS CENTROS POBLADOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Intentar extraer una muestra de datos del DBF\n",
    "print(\"🔄 Extrayendo muestra de datos...\")\n",
    "\n",
    "try:\n",
    "    with open(DBF_PATH, 'rb') as f:\n",
    "        # Saltar header (32 bytes) + descriptores de campos (13 * 32 bytes) + terminador (1 byte)\n",
    "        header_size = 32 + 13 * 32 + 1\n",
    "        f.seek(header_size)\n",
    "        \n",
    "        print(f\"📋 MUESTRA DE DATOS (primeros 5 registros):\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for record_num in range(min(5, num_records)):\n",
    "            # Leer un registro\n",
    "            record = f.read(record_length)\n",
    "            if len(record) >= record_length:\n",
    "                # Procesar el registro (simplificado)\n",
    "                # El primer byte es el indicador de borrado\n",
    "                if record[0] != ord('*'):  # No está borrado\n",
    "                    \n",
    "                    # Extraer campos básicos (aproximado, puede variar según la estructura exacta)\n",
    "                    try:\n",
    "                        # Campo OBJECTID (posición aproximada)\n",
    "                        object_id = record[1:11].decode('utf-8', errors='ignore').strip()\n",
    "                        \n",
    "                        # Campo NOM_POBLAD (posición aproximada)\n",
    "                        nom_poblad = record[11:71].decode('utf-8', errors='ignore').strip()\n",
    "                        \n",
    "                        # Campo X (coordenada - posición aproximada)\n",
    "                        x_start = 1 + 10 + 60 + 5 + 10 + 25 + 60 + 50 + 50 + 4 + 25  # Suma de longitudes anteriores\n",
    "                        x_raw = record[x_start:x_start+19].decode('utf-8', errors='ignore').strip()\n",
    "                        \n",
    "                        # Campo Y (coordenada - posición aproximada)\n",
    "                        y_start = x_start + 19\n",
    "                        y_raw = record[y_start:y_start+19].decode('utf-8', errors='ignore').strip()\n",
    "                        \n",
    "                        print(f\"   {record_num + 1}. ID: {object_id}\")\n",
    "                        print(f\"      📍 Nombre: {nom_poblad[:40]}{'...' if len(nom_poblad) > 40 else ''}\")\n",
    "                        print(f\"      🌍 Coordenada X: {x_raw}\")\n",
    "                        print(f\"      🌍 Coordenada Y: {y_raw}\")\n",
    "                        print()\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"      ⚠️  Error procesando registro {record_num + 1}: {str(e)[:30]}...\")\n",
    "                        \n",
    "    print(\"✅ Extracción de muestra completada!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error extrayendo datos: {e}\")\n",
    "\n",
    "print(f\"\\n🗺️ INFORMACIÓN SOBRE LAS COORDENADAS:\")\n",
    "print(f\"   📐 Las columnas X e Y contienen coordenadas geográficas\")\n",
    "print(f\"   🌍 Estas coordenadas representan la ubicación exacta de cada centro poblado\")\n",
    "print(f\"   📊 Hay {num_records:,} centros poblados con sus respectivas coordenadas\")\n",
    "\n",
    "print(f\"\\n📋 COLUMNAS DISPONIBLES PARA ANÁLISIS:\")\n",
    "print(f\"   1. 📍 NOM_POBLAD - Nombre del centro poblado\")\n",
    "print(f\"   2. 🏛️  DIST - Distrito\")\n",
    "print(f\"   3. 🗺️  PROV - Provincia\") \n",
    "print(f\"   4. 🏴 DEP - Departamento\")\n",
    "print(f\"   5. 🏷️  CATEGORIA - Categoría del centro poblado\")\n",
    "print(f\"   6. 🌍 X, Y - Coordenadas geográficas (CLAVE PARA TU ANÁLISIS)\")\n",
    "\n",
    "print(f\"\\n🎯 PARA TU ANÁLISIS DE RIESGO HÍDRICO:\")\n",
    "print(f\"   • Puedes usar las coordenadas X, Y para ubicar geográficamente los centros poblados\")\n",
    "print(f\"   • Cruzar con tus datos de monitoreo de agua usando proximidad geográfica\")\n",
    "print(f\"   • Identificar qué centros poblados están cerca de zonas de alto riesgo\")\n",
    "print(f\"   • Analizar por departamento, provincia o distrito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183c4356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 CONVIRTIENDO SHAPEFILE A FORMATO TABULAR\n",
      "============================================================\n",
      "🔄 Instalando pyshp para leer shapefiles...\n",
      "Requirement already satisfied: pyshp in /Users/jleandrojm/anaconda3/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: pyshp in /Users/jleandrojm/anaconda3/lib/python3.11/site-packages (2.3.1)\n",
      "✅ pyshp instalado exitosamente\n",
      "✅ pyshp instalado exitosamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/fx/n685hk8x7534hjymvry9354c0000gn/T/ipykernel_19430/400711989.py\", line 18, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/compat/__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/fx/n685hk8x7534hjymvry9354c0000gn/T/ipykernel_19430/400711989.py\", line 18, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/fx/n685hk8x7534hjymvry9354c0000gn/T/ipykernel_19430/400711989.py\", line 18, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/fx/n685hk8x7534hjymvry9354c0000gn/T/ipykernel_19430/400711989.py\", line 18, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/jleandrojm/anaconda3/lib/python3.11/site-packages/bottleneck/__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Leyendo shapefile con pyshp...\n",
      "✅ Shapefile abierto exitosamente!\n",
      "📊 Número de registros: 136,587\n",
      "📐 Tipo de geometría: 1\n",
      "📏 Límites: [-81.31011402699994, -18.344071732999964, -68.65995945699996, -0.030712728999958472]\n",
      "📋 Campos: ['OBJECTID', 'NOM_POBLAD', 'FUENTE', 'CÓDIGO', 'CAT_POBLAD', 'DIST', 'PROV', 'DEP', 'CÓD_INT', 'CATEGORIA', 'X', 'Y', 'N_BUSQDA']\n",
      "\n",
      "🔄 Extrayendo muestra de 1000 registros...\n",
      "✅ Muestra extraída: 1,000 registros\n",
      "📋 Columnas disponibles: ['OBJECTID', 'NOM_POBLAD', 'FUENTE', 'CÓDIGO', 'CAT_POBLAD', 'DIST', 'PROV', 'DEP', 'CÓD_INT', 'CATEGORIA', 'X', 'Y', 'N_BUSQDA', 'COORD_X', 'COORD_Y']\n",
      "\n",
      "📊 INFORMACIÓN DE LA MUESTRA:\n",
      "   📍 Rango de coordenadas X: -76.27700 a -69.57727\n",
      "   📍 Rango de coordenadas Y: -11.49074 a -10.00100\n",
      "\n",
      "👀 PRIMERAS 5 FILAS:\n",
      "    NOM_POBLAD      DIST      DEP    COORD_X    COORD_Y\n",
      "0   PANDISHARI  RAYMONDI  UCAYALI -74.064617 -10.371287\n",
      "1      CHICOSA  RAYMONDI  UCAYALI -74.061529 -10.378517\n",
      "2         RAYA  RAYMONDI  UCAYALI -72.941178 -10.330434\n",
      "3  PENSILVANIA  RAYMONDI  UCAYALI -74.059879 -10.404008\n",
      "4  PONTE VEDRA  RAYMONDI  UCAYALI -74.037875 -10.418090\n",
      "\n",
      "🏴 DISTRIBUCIÓN POR DEPARTAMENTO (Top 10):\n",
      "   • JUNÍN: 754 centros poblados\n",
      "   • UCAYALI: 227 centros poblados\n",
      "   • CUSCO: 14 centros poblados\n",
      "   • MADRE DE DIOS: 3 centros poblados\n",
      "   • PASCO: 2 centros poblados\n",
      "\n",
      "💾 OPCIONES PARA EXPORTAR:\n",
      "   1. 💿 Guardar como CSV: df_ccpp_sample.to_csv('centros_poblados.csv')\n",
      "   2. 🔗 Usar para análisis geoespacial con tus datos de agua\n",
      "   3. 📊 Crear visualizaciones de distribución geográfica\n",
      "✅ Muestra extraída: 1,000 registros\n",
      "📋 Columnas disponibles: ['OBJECTID', 'NOM_POBLAD', 'FUENTE', 'CÓDIGO', 'CAT_POBLAD', 'DIST', 'PROV', 'DEP', 'CÓD_INT', 'CATEGORIA', 'X', 'Y', 'N_BUSQDA', 'COORD_X', 'COORD_Y']\n",
      "\n",
      "📊 INFORMACIÓN DE LA MUESTRA:\n",
      "   📍 Rango de coordenadas X: -76.27700 a -69.57727\n",
      "   📍 Rango de coordenadas Y: -11.49074 a -10.00100\n",
      "\n",
      "👀 PRIMERAS 5 FILAS:\n",
      "    NOM_POBLAD      DIST      DEP    COORD_X    COORD_Y\n",
      "0   PANDISHARI  RAYMONDI  UCAYALI -74.064617 -10.371287\n",
      "1      CHICOSA  RAYMONDI  UCAYALI -74.061529 -10.378517\n",
      "2         RAYA  RAYMONDI  UCAYALI -72.941178 -10.330434\n",
      "3  PENSILVANIA  RAYMONDI  UCAYALI -74.059879 -10.404008\n",
      "4  PONTE VEDRA  RAYMONDI  UCAYALI -74.037875 -10.418090\n",
      "\n",
      "🏴 DISTRIBUCIÓN POR DEPARTAMENTO (Top 10):\n",
      "   • JUNÍN: 754 centros poblados\n",
      "   • UCAYALI: 227 centros poblados\n",
      "   • CUSCO: 14 centros poblados\n",
      "   • MADRE DE DIOS: 3 centros poblados\n",
      "   • PASCO: 2 centros poblados\n",
      "\n",
      "💾 OPCIONES PARA EXPORTAR:\n",
      "   1. 💿 Guardar como CSV: df_ccpp_sample.to_csv('centros_poblados.csv')\n",
      "   2. 🔗 Usar para análisis geoespacial con tus datos de agua\n",
      "   3. 📊 Crear visualizaciones de distribución geográfica\n"
     ]
    }
   ],
   "source": [
    "# 💾 CONVERTIR A FORMATO TABULAR (CSV/DataFrame)\n",
    "print(\"💾 CONVIRTIENDO SHAPEFILE A FORMATO TABULAR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Definir la ruta del shapefile\n",
    "SHAPEFILE_PATH = '../CCPP_0/CCPP_IGN100K.shp'\n",
    "\n",
    "# Instalar y usar pyshp como alternativa más simple\n",
    "print(\"🔄 Instalando pyshp para leer shapefiles...\")\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pyshp\"])\n",
    "    print(\"✅ pyshp instalado exitosamente\")\n",
    "    \n",
    "    import shapefile\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Leer el shapefile\n",
    "    print(\"🔄 Leyendo shapefile con pyshp...\")\n",
    "    \n",
    "    with shapefile.Reader(SHAPEFILE_PATH) as shp:\n",
    "        # Obtener información básica\n",
    "        print(f\"✅ Shapefile abierto exitosamente!\")\n",
    "        print(f\"📊 Número de registros: {len(shp):,}\")\n",
    "        print(f\"📐 Tipo de geometría: {shp.shapeType}\")\n",
    "        print(f\"📏 Límites: {shp.bbox}\")\n",
    "        \n",
    "        # Obtener nombres de campos\n",
    "        field_names = [field[0] for field in shp.fields[1:]]  # El primer campo es siempre 'DeletionFlag'\n",
    "        print(f\"📋 Campos: {field_names}\")\n",
    "        \n",
    "        # Crear DataFrame con una muestra\n",
    "        print(f\"\\n🔄 Extrayendo muestra de 1000 registros...\")\n",
    "        \n",
    "        records_sample = []\n",
    "        coords_sample = []\n",
    "        \n",
    "        # Leer una muestra de registros\n",
    "        for i, (record, shape) in enumerate(zip(shp.records(), shp.shapes())):\n",
    "            if i >= 1000:  # Solo procesar 1000 registros como muestra\n",
    "                break\n",
    "                \n",
    "            # Extraer coordenadas del punto\n",
    "            if shape.points:\n",
    "                x, y = shape.points[0]  # Primer punto (para puntos, solo hay uno)\n",
    "                coords_sample.append([x, y])\n",
    "                \n",
    "                # Agregar record con coordenadas\n",
    "                record_dict = dict(zip(field_names, record))\n",
    "                record_dict['COORD_X'] = x\n",
    "                record_dict['COORD_Y'] = y\n",
    "                records_sample.append(record_dict)\n",
    "        \n",
    "        # Crear DataFrame\n",
    "        df_ccpp_sample = pd.DataFrame(records_sample)\n",
    "        \n",
    "        print(f\"✅ Muestra extraída: {len(df_ccpp_sample):,} registros\")\n",
    "        print(f\"📋 Columnas disponibles: {list(df_ccpp_sample.columns)}\")\n",
    "        \n",
    "        # Mostrar información de la muestra\n",
    "        print(f\"\\n📊 INFORMACIÓN DE LA MUESTRA:\")\n",
    "        print(f\"   📍 Rango de coordenadas X: {df_ccpp_sample['COORD_X'].min():.5f} a {df_ccpp_sample['COORD_X'].max():.5f}\")\n",
    "        print(f\"   📍 Rango de coordenadas Y: {df_ccpp_sample['COORD_Y'].min():.5f} a {df_ccpp_sample['COORD_Y'].max():.5f}\")\n",
    "        \n",
    "        # Mostrar primeras filas\n",
    "        print(f\"\\n👀 PRIMERAS 5 FILAS:\")\n",
    "        display_cols = ['NOM_POBLAD', 'DIST', 'DEP', 'COORD_X', 'COORD_Y']\n",
    "        print(df_ccpp_sample[display_cols].head())\n",
    "        \n",
    "        # Análisis por departamento\n",
    "        print(f\"\\n🏴 DISTRIBUCIÓN POR DEPARTAMENTO (Top 10):\")\n",
    "        dep_counts = df_ccpp_sample['DEP'].value_counts().head(10)\n",
    "        for dep, count in dep_counts.items():\n",
    "            print(f\"   • {dep}: {count:,} centros poblados\")\n",
    "        \n",
    "        print(f\"\\n💾 OPCIONES PARA EXPORTAR:\")\n",
    "        print(f\"   1. 💿 Guardar como CSV: df_ccpp_sample.to_csv('centros_poblados.csv')\")\n",
    "        print(f\"   2. 🔗 Usar para análisis geoespacial con tus datos de agua\")\n",
    "        print(f\"   3. 📊 Crear visualizaciones de distribución geográfica\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    print(\"💡 Método alternativo disponible si es necesario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4d22050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORIA\n",
       "Centro Poblado Menor    987\n",
       "Capital de Distrito      13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ccpp_sample['CATEGORIA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b38a384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 RESUMEN COMPLETO DE TUS DATOS DE CENTROS POBLADOS\n",
      "============================================================\n",
      "🗂️ DATOS TOTALES DISPONIBLES:\n",
      "   📁 Archivo completo: 136,587 centros poblados\n",
      "   📊 Muestra cargada: 1,000 registros\n",
      "   📈 Porcentaje de muestra: 0.73%\n",
      "\n",
      "🌍 COORDENADAS DISPONIBLES:\n",
      "   • En la muestra: 1,000 pares de coordenadas (X, Y)\n",
      "   • En total disponibles: 136,587 pares de coordenadas\n",
      "\n",
      "📍 INFORMACIÓN DE COORDENADAS (MUESTRA):\n",
      "   • Coordenada X (Longitud): -76.277002 a -69.577269\n",
      "   • Coordenada Y (Latitud): -11.490744 a -10.001002\n",
      "\n",
      "📋 EJEMPLO DE COORDENADAS (primeras 10):\n",
      "             NOM_POBLAD    COORD_X    COORD_Y\n",
      "0            PANDISHARI -74.064617 -10.371287\n",
      "1               CHICOSA -74.061529 -10.378517\n",
      "2                  RAYA -72.941178 -10.330434\n",
      "3           PENSILVANIA -74.059879 -10.404008\n",
      "4           PONTE VEDRA -74.037875 -10.418090\n",
      "5               GALILEA -73.985168 -10.453842\n",
      "6         NUEVO EL POZO -74.026564 -10.463330\n",
      "7           BOCA COCANI -74.023100 -10.478250\n",
      "8      PUERTO ESPERANZA -73.973340 -10.472008\n",
      "9  TAHUARAPA SHEREMASHI -73.977674 -10.489965\n",
      "\n",
      "🎯 PARA OBTENER TODAS LAS COORDENADAS (136,587 registros):\n",
      "   1. 🔄 Usar el código de abajo para extraer todo el dataset\n",
      "   2. ⚠️  Advertencia: Cargar todos los registros puede tomar varios minutos\n",
      "   3. 💾 Recomendación: Exportar a CSV para uso futuro\n"
     ]
    }
   ],
   "source": [
    "# 📊 INFORMACIÓN COMPLETA DE TUS DATOS DE CENTROS POBLADOS\n",
    "print(\"📊 RESUMEN COMPLETO DE TUS DATOS DE CENTROS POBLADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"🗂️ DATOS TOTALES DISPONIBLES:\")\n",
    "print(f\"   📁 Archivo completo: {num_records:,} centros poblados\")\n",
    "print(f\"   📊 Muestra cargada: {len(df_ccpp_sample):,} registros\")\n",
    "print(f\"   📈 Porcentaje de muestra: {(len(df_ccpp_sample)/num_records)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n🌍 COORDENADAS DISPONIBLES:\")\n",
    "print(f\"   • En la muestra: {len(df_ccpp_sample):,} pares de coordenadas (X, Y)\")\n",
    "print(f\"   • En total disponibles: {num_records:,} pares de coordenadas\")\n",
    "\n",
    "print(f\"\\n📍 INFORMACIÓN DE COORDENADAS (MUESTRA):\")\n",
    "print(f\"   • Coordenada X (Longitud): {df_ccpp_sample['COORD_X'].min():.6f} a {df_ccpp_sample['COORD_X'].max():.6f}\")\n",
    "print(f\"   • Coordenada Y (Latitud): {df_ccpp_sample['COORD_Y'].min():.6f} a {df_ccpp_sample['COORD_Y'].max():.6f}\")\n",
    "\n",
    "# Mostrar solo las coordenadas\n",
    "coordenadas_muestra = df_ccpp_sample[['NOM_POBLAD', 'COORD_X', 'COORD_Y']].copy()\n",
    "print(f\"\\n📋 EJEMPLO DE COORDENADAS (primeras 10):\")\n",
    "print(coordenadas_muestra.head(10))\n",
    "\n",
    "print(f\"\\n🎯 PARA OBTENER TODAS LAS COORDENADAS ({num_records:,} registros):\")\n",
    "print(f\"   1. 🔄 Usar el código de abajo para extraer todo el dataset\")\n",
    "print(f\"   2. ⚠️  Advertencia: Cargar todos los registros puede tomar varios minutos\")\n",
    "print(f\"   3. 💾 Recomendación: Exportar a CSV para uso futuro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7816efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 EXTRAYENDO TODAS LAS COORDENADAS DEL DATASET COMPLETO\n",
      "============================================================\n",
      "🔄 Procesando 136,587 centros poblados...\n",
      "   ⏳ Esto puede tomar varios minutos...\n",
      "   📊 Procesados: 0 / 136,587 (0.0%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 10,000 / 136,587 (7.3%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 20,000 / 136,587 (14.6%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 30,000 / 136,587 (22.0%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 40,000 / 136,587 (29.3%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 50,000 / 136,587 (36.6%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 60,000 / 136,587 (43.9%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 70,000 / 136,587 (51.2%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 80,000 / 136,587 (58.6%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 90,000 / 136,587 (65.9%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 100,000 / 136,587 (73.2%) - Tiempo: 0.9s\n",
      "   📊 Procesados: 110,000 / 136,587 (80.5%) - Tiempo: 0.9s\n",
      "   📊 Procesados: 120,000 / 136,587 (87.9%) - Tiempo: 0.9s\n",
      "   📊 Procesados: 130,000 / 136,587 (95.2%) - Tiempo: 0.9s\n",
      "\n",
      "✅ EXTRACCIÓN COMPLETADA!\n",
      "   📊 Total procesado: 136,587 centros poblados\n",
      "   ⏱️ Tiempo total: 1.0 segundos\n",
      "   💾 Memoria utilizada: 37.9 MB\n",
      "\n",
      "🌍 COORDENADAS COMPLETAS:\n",
      "   📍 Rango X (Longitud): -81.310114 a -68.659959\n",
      "   📍 Rango Y (Latitud): -18.344072 a -0.030713\n",
      "\n",
      "🏴 DISTRIBUCIÓN POR DEPARTAMENTO (Top 10):\n",
      "   • PUNO: 16,804 centros poblados\n",
      "   • CUSCO: 13,496 centros poblados\n",
      "   • ANCASH: 10,658 centros poblados\n",
      "   • AYACUCHO: 10,081 centros poblados\n",
      "   • HUANUCO: 9,193 centros poblados\n",
      "   • CAJAMARCA: 8,240 centros poblados\n",
      "   • HUANCAVELICA: 8,207 centros poblados\n",
      "   • LIMA: 7,615 centros poblados\n",
      "   • AREQUIPA: 7,059 centros poblados\n",
      "   • JUNÍN: 6,320 centros poblados\n",
      "\n",
      "💾 PARA GUARDAR TODAS LAS COORDENADAS:\n",
      "   # Exportar solo coordenadas\n",
      "   coordenadas_completas = df_ccpp_completo[['NOM_POBLAD', 'COORD_X', 'COORD_Y']]\n",
      "   coordenadas_completas.to_csv('../DATA/coordenadas_centros_poblados_completo.csv', index=False)\n",
      "   \n",
      "   # O exportar todo el dataset\n",
      "   df_ccpp_completo.to_csv('../DATA/centros_poblados_completo.csv', index=False)\n",
      "   📊 Procesados: 0 / 136,587 (0.0%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 10,000 / 136,587 (7.3%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 20,000 / 136,587 (14.6%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 30,000 / 136,587 (22.0%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 40,000 / 136,587 (29.3%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 50,000 / 136,587 (36.6%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 60,000 / 136,587 (43.9%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 70,000 / 136,587 (51.2%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 80,000 / 136,587 (58.6%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 90,000 / 136,587 (65.9%) - Tiempo: 0.8s\n",
      "   📊 Procesados: 100,000 / 136,587 (73.2%) - Tiempo: 0.9s\n",
      "   📊 Procesados: 110,000 / 136,587 (80.5%) - Tiempo: 0.9s\n",
      "   📊 Procesados: 120,000 / 136,587 (87.9%) - Tiempo: 0.9s\n",
      "   📊 Procesados: 130,000 / 136,587 (95.2%) - Tiempo: 0.9s\n",
      "\n",
      "✅ EXTRACCIÓN COMPLETADA!\n",
      "   📊 Total procesado: 136,587 centros poblados\n",
      "   ⏱️ Tiempo total: 1.0 segundos\n",
      "   💾 Memoria utilizada: 37.9 MB\n",
      "\n",
      "🌍 COORDENADAS COMPLETAS:\n",
      "   📍 Rango X (Longitud): -81.310114 a -68.659959\n",
      "   📍 Rango Y (Latitud): -18.344072 a -0.030713\n",
      "\n",
      "🏴 DISTRIBUCIÓN POR DEPARTAMENTO (Top 10):\n",
      "   • PUNO: 16,804 centros poblados\n",
      "   • CUSCO: 13,496 centros poblados\n",
      "   • ANCASH: 10,658 centros poblados\n",
      "   • AYACUCHO: 10,081 centros poblados\n",
      "   • HUANUCO: 9,193 centros poblados\n",
      "   • CAJAMARCA: 8,240 centros poblados\n",
      "   • HUANCAVELICA: 8,207 centros poblados\n",
      "   • LIMA: 7,615 centros poblados\n",
      "   • AREQUIPA: 7,059 centros poblados\n",
      "   • JUNÍN: 6,320 centros poblados\n",
      "\n",
      "💾 PARA GUARDAR TODAS LAS COORDENADAS:\n",
      "   # Exportar solo coordenadas\n",
      "   coordenadas_completas = df_ccpp_completo[['NOM_POBLAD', 'COORD_X', 'COORD_Y']]\n",
      "   coordenadas_completas.to_csv('../DATA/coordenadas_centros_poblados_completo.csv', index=False)\n",
      "   \n",
      "   # O exportar todo el dataset\n",
      "   df_ccpp_completo.to_csv('../DATA/centros_poblados_completo.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "# 🚀 EXTRAER TODAS LAS COORDENADAS (136,587 REGISTROS)\n",
    "print(\"🚀 EXTRAYENDO TODAS LAS COORDENADAS DEL DATASET COMPLETO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"🔄 Procesando {num_records:,} centros poblados...\")\n",
    "print(\"   ⏳ Esto puede tomar varios minutos...\")\n",
    "\n",
    "try:\n",
    "    with shapefile.Reader(SHAPEFILE_PATH) as shp:\n",
    "        \n",
    "        # Obtener nombres de campos\n",
    "        field_names = [field[0] for field in shp.fields[1:]]\n",
    "        \n",
    "        # Inicializar listas para almacenar datos\n",
    "        all_records = []\n",
    "        total_processed = 0\n",
    "        \n",
    "        # Procesar todos los registros\n",
    "        for i, (record, shape) in enumerate(zip(shp.records(), shp.shapes())):\n",
    "            \n",
    "            # Mostrar progreso cada 10,000 registros\n",
    "            if i % 10000 == 0:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"   📊 Procesados: {i:,} / {num_records:,} ({(i/num_records)*100:.1f}%) - Tiempo: {elapsed_time:.1f}s\")\n",
    "            \n",
    "            # Extraer coordenadas del punto\n",
    "            if shape.points:\n",
    "                x, y = shape.points[0]  # Primer punto (para puntos, solo hay uno)\n",
    "                \n",
    "                # Solo guardar los datos esenciales: nombre y coordenadas\n",
    "                record_data = {\n",
    "                    'OBJECTID': record[0] if len(record) > 0 else None,\n",
    "                    'NOM_POBLAD': record[1] if len(record) > 1 else None,\n",
    "                    'DIST': record[5] if len(record) > 5 else None,\n",
    "                    'PROV': record[6] if len(record) > 6 else None,\n",
    "                    'DEP': record[7] if len(record) > 7 else None,\n",
    "                    'COORD_X': x,\n",
    "                    'COORD_Y': y\n",
    "                }\n",
    "                \n",
    "                all_records.append(record_data)\n",
    "                total_processed += 1\n",
    "        \n",
    "        # Crear DataFrame con todos los datos\n",
    "        df_ccpp_completo = pd.DataFrame(all_records)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\n✅ EXTRACCIÓN COMPLETADA!\")\n",
    "        print(f\"   📊 Total procesado: {len(df_ccpp_completo):,} centros poblados\")\n",
    "        print(f\"   ⏱️ Tiempo total: {elapsed_time:.1f} segundos\")\n",
    "        print(f\"   💾 Memoria utilizada: {df_ccpp_completo.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "        \n",
    "        # Información de las coordenadas completas\n",
    "        print(f\"\\n🌍 COORDENADAS COMPLETAS:\")\n",
    "        print(f\"   📍 Rango X (Longitud): {df_ccpp_completo['COORD_X'].min():.6f} a {df_ccpp_completo['COORD_X'].max():.6f}\")\n",
    "        print(f\"   📍 Rango Y (Latitud): {df_ccpp_completo['COORD_Y'].min():.6f} a {df_ccpp_completo['COORD_Y'].max():.6f}\")\n",
    "        \n",
    "        # Estadísticas por departamento\n",
    "        print(f\"\\n🏴 DISTRIBUCIÓN POR DEPARTAMENTO (Top 10):\")\n",
    "        dep_counts_completo = df_ccpp_completo['DEP'].value_counts().head(10)\n",
    "        for dep, count in dep_counts_completo.items():\n",
    "            print(f\"   • {dep}: {count:,} centros poblados\")\n",
    "        \n",
    "        print(f\"\\n💾 PARA GUARDAR TODAS LAS COORDENADAS:\")\n",
    "        print(f\"   # Exportar solo coordenadas\")\n",
    "        print(f\"   coordenadas_completas = df_ccpp_completo[['NOM_POBLAD', 'COORD_X', 'COORD_Y']]\")\n",
    "        print(f\"   coordenadas_completas.to_csv('../DATA/coordenadas_centros_poblados_completo.csv', index=False)\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # O exportar todo el dataset\")\n",
    "        print(f\"   df_ccpp_completo.to_csv('../DATA/centros_poblados_completo.csv', index=False)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error durante la extracción: {e}\")\n",
    "    print(\"💡 Si hay problemas de memoria, usa la muestra de 1000 registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b61dfac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 GUARDANDO COORDENADAS Y MOSTRANDO RESUMEN FINAL\n",
      "============================================================\n",
      "📊 RESUMEN FINAL DE TUS COORDENADAS:\n",
      "   🗂️ Total de centros poblados: 136,587\n",
      "   🌍 Total de coordenadas: 136,587 pares (X, Y)\n",
      "   📐 Cobertura geográfica completa del Perú\n",
      "\n",
      "🌍 RANGO GEOGRÁFICO COMPLETO:\n",
      "   📍 Longitud (X): -81.310114 a -68.659959\n",
      "   📍 Latitud (Y): -18.344072 a -0.030713\n",
      "\n",
      "📋 MUESTRA DE COORDENADAS (primeras 10):\n",
      "             NOM_POBLAD    COORD_X    COORD_Y\n",
      "0            PANDISHARI -74.064617 -10.371287\n",
      "1               CHICOSA -74.061529 -10.378517\n",
      "2                  RAYA -72.941178 -10.330434\n",
      "3           PENSILVANIA -74.059879 -10.404008\n",
      "4           PONTE VEDRA -74.037875 -10.418090\n",
      "5               GALILEA -73.985168 -10.453842\n",
      "6         NUEVO EL POZO -74.026564 -10.463330\n",
      "7           BOCA COCANI -74.023100 -10.478250\n",
      "8      PUERTO ESPERANZA -73.973340 -10.472008\n",
      "9  TAHUARAPA SHEREMASHI -73.977674 -10.489965\n",
      "\n",
      "📈 ESTADÍSTICAS:\n",
      "   • Departamentos cubiertos: 28\n",
      "   • Provincias cubiertas: 208\n",
      "   • Distritos cubiertos: 1790\n",
      "\n",
      "💾 GUARDANDO ARCHIVOS:\n",
      "   ✅ Coordenadas guardadas: ../DATA/coordenadas_centros_poblados_completo.csv\n",
      "   ✅ Dataset completo guardado: ../DATA/centros_poblados_completo.csv\n",
      "\n",
      "📊 ARCHIVOS CREADOS:\n",
      "   📁 ../DATA/coordenadas_centros_poblados_completo.csv\n",
      "      └─ 136,587 filas × 3 columnas (nombre + coordenadas)\n",
      "   📁 ../DATA/centros_poblados_completo.csv\n",
      "      └─ 136,587 filas × 7 columnas (info completa)\n",
      "\n",
      "🎯 LISTO PARA TU ANÁLISIS DE RIESGO HÍDRICO:\n",
      "   • Tienes 136,587 coordenadas de centros poblados\n",
      "   • Datos guardados en formato CSV para fácil uso\n",
      "   • Listos para cruzar con tus datos de monitoreo de agua\n",
      "   • Cobertura completa del territorio peruano\n",
      "\n",
      "🚀 PRÓXIMO PASO: Integrar con tu Radar de Riesgo Hídrico\n"
     ]
    }
   ],
   "source": [
    "# 💾 GUARDAR Y MOSTRAR RESUMEN FINAL\n",
    "print(\"💾 GUARDANDO COORDENADAS Y MOSTRANDO RESUMEN FINAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Crear dataset solo con coordenadas\n",
    "coordenadas_completas = df_ccpp_completo[['NOM_POBLAD', 'COORD_X', 'COORD_Y']].copy()\n",
    "\n",
    "print(f\"📊 RESUMEN FINAL DE TUS COORDENADAS:\")\n",
    "print(f\"   🗂️ Total de centros poblados: {len(df_ccpp_completo):,}\")\n",
    "print(f\"   🌍 Total de coordenadas: {len(coordenadas_completas):,} pares (X, Y)\")\n",
    "print(f\"   📐 Cobertura geográfica completa del Perú\")\n",
    "\n",
    "print(f\"\\n🌍 RANGO GEOGRÁFICO COMPLETO:\")\n",
    "print(f\"   📍 Longitud (X): {df_ccpp_completo['COORD_X'].min():.6f} a {df_ccpp_completo['COORD_X'].max():.6f}\")\n",
    "print(f\"   📍 Latitud (Y): {df_ccpp_completo['COORD_Y'].min():.6f} a {df_ccpp_completo['COORD_Y'].max():.6f}\")\n",
    "\n",
    "print(f\"\\n📋 MUESTRA DE COORDENADAS (primeras 10):\")\n",
    "print(coordenadas_completas.head(10))\n",
    "\n",
    "print(f\"\\n📈 ESTADÍSTICAS:\")\n",
    "print(f\"   • Departamentos cubiertos: {df_ccpp_completo['DEP'].nunique()}\")\n",
    "print(f\"   • Provincias cubiertas: {df_ccpp_completo['PROV'].nunique()}\")\n",
    "print(f\"   • Distritos cubiertos: {df_ccpp_completo['DIST'].nunique()}\")\n",
    "\n",
    "# Guardar archivos\n",
    "print(f\"\\n💾 GUARDANDO ARCHIVOS:\")\n",
    "\n",
    "try:\n",
    "    # Guardar solo coordenadas\n",
    "    coord_file = '../DATA/coordenadas_centros_poblados_completo.csv'\n",
    "    coordenadas_completas.to_csv(coord_file, index=False)\n",
    "    print(f\"   ✅ Coordenadas guardadas: {coord_file}\")\n",
    "    \n",
    "    # Guardar dataset completo\n",
    "    full_file = '../DATA/centros_poblados_completo.csv'\n",
    "    df_ccpp_completo.to_csv(full_file, index=False)\n",
    "    print(f\"   ✅ Dataset completo guardado: {full_file}\")\n",
    "    \n",
    "    print(f\"\\n📊 ARCHIVOS CREADOS:\")\n",
    "    print(f\"   📁 {coord_file}\")\n",
    "    print(f\"      └─ {len(coordenadas_completas):,} filas × 3 columnas (nombre + coordenadas)\")\n",
    "    print(f\"   📁 {full_file}\") \n",
    "    print(f\"      └─ {len(df_ccpp_completo):,} filas × {len(df_ccpp_completo.columns)} columnas (info completa)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Error guardando archivos: {e}\")\n",
    "    print(f\"   💡 Verifica que la carpeta DATA/ exista\")\n",
    "\n",
    "print(f\"\\n🎯 LISTO PARA TU ANÁLISIS DE RIESGO HÍDRICO:\")\n",
    "print(f\"   • Tienes {len(coordenadas_completas):,} coordenadas de centros poblados\")\n",
    "print(f\"   • Datos guardados en formato CSV para fácil uso\")\n",
    "print(f\"   • Listos para cruzar con tus datos de monitoreo de agua\")\n",
    "print(f\"   • Cobertura completa del territorio peruano\")\n",
    "\n",
    "print(f\"\\n🚀 PRÓXIMO PASO: Integrar con tu Radar de Riesgo Hídrico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584086c",
   "metadata": {},
   "source": [
    "## 🎯 RESUMEN EJECUTIVO Y PRÓXIMOS PASOS\n",
    "\n",
    "### ✅ **LO QUE HEMOS DESCUBIERTO:**\n",
    "\n",
    "Tu archivo `CCPP_0` contiene un **Shapefile con datos geoespaciales** de **136,587 centros poblados** del Perú, incluyendo:\n",
    "\n",
    "#### 📊 **Datos Disponibles:**\n",
    "- **📍 Coordenadas exactas** (X, Y) de cada centro poblado\n",
    "- **🏷️ Nombres** de centros poblados\n",
    "- **🗺️ División administrativa** (Departamento, Provincia, Distrito)\n",
    "- **🏘️ Categoría** del centro poblado\n",
    "\n",
    "#### 🌍 **Coordenadas Geográficas:**\n",
    "- **Formato**: Latitud/Longitud decimal\n",
    "- **Cobertura**: Todo el territorio peruano\n",
    "- **Precisión**: Coordenadas exactas para ubicación geoespacial\n",
    "\n",
    "### 🚀 **INTEGRACIÓN CON TU RADAR DE RIESGO HÍDRICO:**\n",
    "\n",
    "Estos datos de centros poblados son **PERFECTOS** para tu análisis porque te permiten:\n",
    "\n",
    "1. **🎯 Identificar población en riesgo**: Saber qué centros poblados están cerca de zonas de contaminación\n",
    "2. **📏 Calcular proximidad**: Determinar distancia entre centros poblados y puntos de monitoreo de agua\n",
    "3. **📊 Priorizar intervenciones**: Enfocar recursos en áreas con mayor densidad poblacional\n",
    "4. **🗺️ Visualizar geográficamente**: Crear mapas de riesgo que muestren población afectada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e229cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 CÓMO INTEGRAR CON TU RADAR DE RIESGO HÍDRICO\n",
      "============================================================\n",
      "💡 EJEMPLO DE CÓDIGO PARA INTEGRACIÓN:\n",
      "----------------------------------------\n",
      "\n",
      "# 1. Cargar ambos datasets\n",
      "df_centros_poblados = df_ccpp_sample  # Del shapefile\n",
      "df_agua_superficial = df_agua_superficial  # De tu análisis anterior\n",
      "\n",
      "# 2. Función para calcular proximidad geográfica\n",
      "from math import radians, cos, sin, asin, sqrt\n",
      "\n",
      "def calcular_distancia(lat1, lon1, lat2, lon2):\n",
      "    \"\"\"Calcular distancia en km entre dos puntos\"\"\"\n",
      "    R = 6371  # Radio de la Tierra en km\n",
      "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
      "    dlat = lat2 - lat1\n",
      "    dlon = lon2 - lon1\n",
      "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
      "    return 2 * R * asin(sqrt(a))\n",
      "\n",
      "# 3. Encontrar centros poblados cerca de puntos de monitoreo\n",
      "def encontrar_poblados_en_riesgo(df_poblados, df_agua, radio_km=10):\n",
      "    poblados_riesgo = []\n",
      "    \n",
      "    for _, punto_agua in df_agua.iterrows():\n",
      "        if pd.notna(punto_agua['COORD_ESTE']) and pd.notna(punto_agua['COORD_NORTE']):\n",
      "            for _, poblado in df_poblados.iterrows():\n",
      "                distancia = calcular_distancia(\n",
      "                    punto_agua['COORD_NORTE'], punto_agua['COORD_ESTE'],\n",
      "                    poblado['COORD_Y'], poblado['COORD_X']\n",
      "                )\n",
      "                \n",
      "                if distancia <= radio_km:\n",
      "                    poblados_riesgo.append({\n",
      "                        'poblado': poblado['NOM_POBLAD'],\n",
      "                        'departamento': poblado['DEP'],\n",
      "                        'distrito': poblado['DIST'],\n",
      "                        'distancia_km': distancia,\n",
      "                        'punto_monitoreo': punto_agua['EXPEDIENTE'],\n",
      "                        'coordinacion': punto_agua['COORDINACION']\n",
      "                    })\n",
      "    \n",
      "    return pd.DataFrame(poblados_riesgo)\n",
      "\n",
      "# 4. Ejemplo de uso\n",
      "# poblados_en_riesgo = encontrar_poblados_en_riesgo(df_centros_poblados, df_agua_superficial)\n",
      "\n",
      "\n",
      "🎯 MÉTRICAS QUE PUEDES CALCULAR:\n",
      "   • 👥 Población en riesgo por zona de contaminación\n",
      "   • 📏 Distancia promedio entre centros poblados y puntos de monitoreo\n",
      "   • 🗺️ Departamentos/provincias con mayor exposición\n",
      "   • 🚨 Centros poblados en zona de riesgo crítico\n",
      "\n",
      "📊 POTENCIAL DE TUS DATOS:\n",
      "   • 1,000 centros poblados (muestra)\n",
      "   • Coordenadas precisas para análisis geoespacial\n",
      "   • División administrativa completa\n",
      "   • Listo para cruzar con datos de monitoreo de agua\n",
      "\n",
      "💾 PARA GUARDAR LOS DATOS:\n",
      "   # Exportar a CSV para uso posterior\n",
      "   df_ccpp_sample.to_csv('../DATA/centros_poblados_muestra.csv', index=False)\n",
      "   # O cargar todo el shapefile si necesitas más datos\n",
      "\n",
      "🚀 PRÓXIMO PASO RECOMENDADO:\n",
      "   Integrar estos datos de población con tu análisis de hotspots\n",
      "   para crear un 'Radar de Riesgo Poblacional' más completo\n"
     ]
    }
   ],
   "source": [
    "# 🔗 EJEMPLO DE INTEGRACIÓN CON DATOS DE AGUA\n",
    "print(\"🔗 CÓMO INTEGRAR CON TU RADAR DE RIESGO HÍDRICO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Simulación de cómo combinar con datos de agua\n",
    "print(\"💡 EJEMPLO DE CÓDIGO PARA INTEGRACIÓN:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "ejemplo_codigo = '''\n",
    "# 1. Cargar ambos datasets\n",
    "df_centros_poblados = df_ccpp_sample  # Del shapefile\n",
    "df_agua_superficial = df_agua_superficial  # De tu análisis anterior\n",
    "\n",
    "# 2. Función para calcular proximidad geográfica\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def calcular_distancia(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calcular distancia en km entre dos puntos\"\"\"\n",
    "    R = 6371  # Radio de la Tierra en km\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    return 2 * R * asin(sqrt(a))\n",
    "\n",
    "# 3. Encontrar centros poblados cerca de puntos de monitoreo\n",
    "def encontrar_poblados_en_riesgo(df_poblados, df_agua, radio_km=10):\n",
    "    poblados_riesgo = []\n",
    "    \n",
    "    for _, punto_agua in df_agua.iterrows():\n",
    "        if pd.notna(punto_agua['COORD_ESTE']) and pd.notna(punto_agua['COORD_NORTE']):\n",
    "            for _, poblado in df_poblados.iterrows():\n",
    "                distancia = calcular_distancia(\n",
    "                    punto_agua['COORD_NORTE'], punto_agua['COORD_ESTE'],\n",
    "                    poblado['COORD_Y'], poblado['COORD_X']\n",
    "                )\n",
    "                \n",
    "                if distancia <= radio_km:\n",
    "                    poblados_riesgo.append({\n",
    "                        'poblado': poblado['NOM_POBLAD'],\n",
    "                        'departamento': poblado['DEP'],\n",
    "                        'distrito': poblado['DIST'],\n",
    "                        'distancia_km': distancia,\n",
    "                        'punto_monitoreo': punto_agua['EXPEDIENTE'],\n",
    "                        'coordinacion': punto_agua['COORDINACION']\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(poblados_riesgo)\n",
    "\n",
    "# 4. Ejemplo de uso\n",
    "# poblados_en_riesgo = encontrar_poblados_en_riesgo(df_centros_poblados, df_agua_superficial)\n",
    "'''\n",
    "\n",
    "print(ejemplo_codigo)\n",
    "\n",
    "print(\"\\n🎯 MÉTRICAS QUE PUEDES CALCULAR:\")\n",
    "print(\"   • 👥 Población en riesgo por zona de contaminación\")\n",
    "print(\"   • 📏 Distancia promedio entre centros poblados y puntos de monitoreo\")\n",
    "print(\"   • 🗺️ Departamentos/provincias con mayor exposición\")\n",
    "print(\"   • 🚨 Centros poblados en zona de riesgo crítico\")\n",
    "\n",
    "print(f\"\\n📊 POTENCIAL DE TUS DATOS:\")\n",
    "print(f\"   • {len(df_ccpp_sample):,} centros poblados (muestra)\")\n",
    "print(f\"   • Coordenadas precisas para análisis geoespacial\")\n",
    "print(f\"   • División administrativa completa\")\n",
    "print(f\"   • Listo para cruzar con datos de monitoreo de agua\")\n",
    "\n",
    "print(f\"\\n💾 PARA GUARDAR LOS DATOS:\")\n",
    "print(f\"   # Exportar a CSV para uso posterior\")\n",
    "print(f\"   df_ccpp_sample.to_csv('../DATA/centros_poblados_muestra.csv', index=False)\")\n",
    "print(f\"   # O cargar todo el shapefile si necesitas más datos\")\n",
    "\n",
    "print(f\"\\n🚀 PRÓXIMO PASO RECOMENDADO:\")\n",
    "print(f\"   Integrar estos datos de población con tu análisis de hotspots\")\n",
    "print(f\"   para crear un 'Radar de Riesgo Poblacional' más completo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc234bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 PROCESAMIENTO FINAL PARA HACKATON - CENTROS POBLADOS\n",
      "=================================================================\n",
      "📋 SELECCIONANDO COLUMNAS ESENCIALES PARA LA HACKATON...\n",
      "✅ Centros poblados cargados: 136,587\n",
      "\n",
      "🔍 COLUMNAS DISPONIBLES:\n",
      "   ['OBJECTID', 'NOM_POBLAD', 'DIST', 'PROV', 'DEP', 'COORD_X', 'COORD_Y']\n",
      "\n",
      "🔍 RANGOS ACTUALES DE COORDENADAS:\n",
      "   • Longitud (COORD_X): -81.310114 a -68.659959\n",
      "   • Latitud (COORD_Y): -18.344072 a -0.030713\n",
      "\n",
      "📋 COLUMNAS SELECCIONADAS:\n",
      "   • OBJECTID → id_centro_poblado\n",
      "   • NOM_POBLAD → nombre_centro_poblado\n",
      "   • DIST → distrito\n",
      "   • PROV → provincia\n",
      "   • DEP → departamento\n",
      "   • COORD_X → longitud\n",
      "   • COORD_Y → latitud\n",
      "\n",
      "📊 DATASET PROCESADO:\n",
      "   • Registros: 136,587\n",
      "   • Columnas: 7\n",
      "   • Memoria: 37.9 MB\n",
      "\n",
      "📝 COLUMNAS FINALES:\n",
      "    1. id_centro_poblado: 136,587 registros (100.0% completo)\n",
      "    2. nombre_centro_poblado: 136,587 registros (100.0% completo)\n",
      "    3. distrito: 136,587 registros (100.0% completo)\n",
      "    4. provincia: 136,587 registros (100.0% completo)\n",
      "    5. departamento: 136,587 registros (100.0% completo)\n",
      "    6. longitud: 136,587 registros (100.0% completo)\n",
      "    7. latitud: 136,587 registros (100.0% completo)\n",
      "\n",
      "📋 MUESTRA DEL DATASET INICIAL:\n",
      "   id_centro_poblado nombre_centro_poblado  distrito provincia departamento  \\\n",
      "0                  1            PANDISHARI  RAYMONDI   ATALAYA      UCAYALI   \n",
      "1                  2               CHICOSA  RAYMONDI   ATALAYA      UCAYALI   \n",
      "2                  3                  RAYA  RAYMONDI   ATALAYA      UCAYALI   \n",
      "3                  4           PENSILVANIA  RAYMONDI   ATALAYA      UCAYALI   \n",
      "4                  5           PONTE VEDRA  RAYMONDI   ATALAYA      UCAYALI   \n",
      "\n",
      "    longitud    latitud  \n",
      "0 -74.064617 -10.371287  \n",
      "1 -74.061529 -10.378517  \n",
      "2 -72.941178 -10.330434  \n",
      "3 -74.059879 -10.404008  \n",
      "4 -74.037875 -10.418090  \n"
     ]
    }
   ],
   "source": [
    "# 🎯 PROCESAMIENTO FINAL PARA HACKATON - DATASET CENTROS POBLADOS\n",
    "print(\"🎯 PROCESAMIENTO FINAL PARA HACKATON - CENTROS POBLADOS\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "print(\"📋 SELECCIONANDO COLUMNAS ESENCIALES PARA LA HACKATON...\")\n",
    "\n",
    "# Ya tenemos el dataset completo cargado en df_ccpp_completo\n",
    "print(f\"✅ Centros poblados cargados: {len(df_ccpp_completo):,}\")\n",
    "\n",
    "print(f\"\\n🔍 COLUMNAS DISPONIBLES:\")\n",
    "print(f\"   {list(df_ccpp_completo.columns)}\")\n",
    "\n",
    "print(f\"\\n🔍 RANGOS ACTUALES DE COORDENADAS:\")\n",
    "print(f\"   • Longitud (COORD_X): {df_ccpp_completo['COORD_X'].min():.6f} a {df_ccpp_completo['COORD_X'].max():.6f}\")\n",
    "print(f\"   • Latitud (COORD_Y): {df_ccpp_completo['COORD_Y'].min():.6f} a {df_ccpp_completo['COORD_Y'].max():.6f}\")\n",
    "\n",
    "# Seleccionar y renombrar columnas esenciales para la hackaton (ajustado a las columnas disponibles)\n",
    "columnas_esenciales = {\n",
    "    'OBJECTID': 'id_centro_poblado',\n",
    "    'NOM_POBLAD': 'nombre_centro_poblado',\n",
    "    'DIST': 'distrito',\n",
    "    'PROV': 'provincia', \n",
    "    'DEP': 'departamento',\n",
    "    'COORD_X': 'longitud',\n",
    "    'COORD_Y': 'latitud'\n",
    "}\n",
    "\n",
    "# Verificar qué columnas existen realmente\n",
    "columnas_disponibles = {}\n",
    "for col_orig, col_nueva in columnas_esenciales.items():\n",
    "    if col_orig in df_ccpp_completo.columns:\n",
    "        columnas_disponibles[col_orig] = col_nueva\n",
    "    else:\n",
    "        print(f\"   ⚠️ Columna {col_orig} no encontrada\")\n",
    "\n",
    "print(f\"\\n📋 COLUMNAS SELECCIONADAS:\")\n",
    "for col_orig, col_nueva in columnas_disponibles.items():\n",
    "    print(f\"   • {col_orig} → {col_nueva}\")\n",
    "\n",
    "# Crear dataset final con solo las columnas disponibles\n",
    "df_poblacion_procesado = df_ccpp_completo[list(columnas_disponibles.keys())].copy()\n",
    "df_poblacion_procesado = df_poblacion_procesado.rename(columns=columnas_disponibles)\n",
    "\n",
    "print(f\"\\n📊 DATASET PROCESADO:\")\n",
    "print(f\"   • Registros: {len(df_poblacion_procesado):,}\")\n",
    "print(f\"   • Columnas: {len(df_poblacion_procesado.columns)}\")\n",
    "print(f\"   • Memoria: {df_poblacion_procesado.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "print(f\"\\n📝 COLUMNAS FINALES:\")\n",
    "for i, col in enumerate(df_poblacion_procesado.columns, 1):\n",
    "    non_null = df_poblacion_procesado[col].notna().sum()\n",
    "    completitud = (non_null / len(df_poblacion_procesado)) * 100\n",
    "    print(f\"   {i:2d}. {col}: {non_null:,} registros ({completitud:.1f}% completo)\")\n",
    "\n",
    "print(f\"\\n📋 MUESTRA DEL DATASET INICIAL:\")\n",
    "print(df_poblacion_procesado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97099c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 VALIDACIÓN DE COORDENADAS Y LIMPIEZA DE DATOS\n",
      "=======================================================\n",
      "🔍 ANÁLISIS DE COORDENADAS ANTES DEL FILTRO:\n",
      "   • Total de centros poblados: 136,587\n",
      "   • Rango longitud: -81.310114 a -68.659959\n",
      "   • Rango latitud: -18.344072 a -0.030713\n",
      "   • Coordenadas (0, 0): 0\n",
      "   • Longitudes nulas: 0\n",
      "   • Latitudes nulas: 0\n",
      "\n",
      "🌍 APLICANDO FILTRO DE COORDENADAS VÁLIDAS PARA PERÚ:\n",
      "   • Longitud: -81.5° a -68.0° (territorio peruano)\n",
      "   • Latitud: -18.5° a 0.5° (territorio peruano)\n",
      "   • Excluyendo coordenadas (0, 0)\n",
      "\n",
      "✅ RESULTADO DEL FILTRO:\n",
      "   • Centros poblados válidos: 136,587\n",
      "   • Centros poblados eliminados: 0\n",
      "   • Porcentaje conservado: 100.00%\n",
      "\n",
      "🗺️ RANGO GEOGRÁFICO DESPUÉS DEL FILTRO:\n",
      "   • Longitud: -81.310114 a -68.659959\n",
      "   • Latitud: -18.344072 a -0.030713\n",
      "\n",
      "🧹 LIMPIEZA Y ESTANDARIZACIÓN DE CAMPOS DE TEXTO:\n",
      "   ✅ Campos de texto estandarizados (mayúsculas, sin espacios extra)\n",
      "\n",
      "📊 ESTADÍSTICAS FINALES:\n",
      "   • Departamentos únicos: 28\n",
      "   • Provincias únicas: 208\n",
      "   • Distritos únicos: 1790\n",
      "\n",
      "🏴 DISTRIBUCIÓN POR DEPARTAMENTO (Top 10):\n",
      "    1. PUNO: 16,804 (12.3%)\n",
      "    2. CUSCO: 13,496 (9.9%)\n",
      "    3. ANCASH: 10,658 (7.8%)\n",
      "    4. AYACUCHO: 10,081 (7.4%)\n",
      "    5. HUANUCO: 9,193 (6.7%)\n",
      "    6. CAJAMARCA: 8,240 (6.0%)\n",
      "    7. HUANCAVELICA: 8,207 (6.0%)\n",
      "    8. LIMA: 7,615 (5.6%)\n",
      "    9. AREQUIPA: 7,059 (5.2%)\n",
      "   10. JUNÍN: 6,320 (4.6%)\n",
      "\n",
      "📋 MUESTRA DEL DATASET LIMPIO:\n",
      "   id_centro_poblado nombre_centro_poblado  distrito provincia departamento  \\\n",
      "0                  1            PANDISHARI  RAYMONDI   ATALAYA      UCAYALI   \n",
      "1                  2               CHICOSA  RAYMONDI   ATALAYA      UCAYALI   \n",
      "2                  3                  RAYA  RAYMONDI   ATALAYA      UCAYALI   \n",
      "3                  4           PENSILVANIA  RAYMONDI   ATALAYA      UCAYALI   \n",
      "4                  5           PONTE VEDRA  RAYMONDI   ATALAYA      UCAYALI   \n",
      "\n",
      "    longitud    latitud  \n",
      "0 -74.064617 -10.371287  \n",
      "1 -74.061529 -10.378517  \n",
      "2 -72.941178 -10.330434  \n",
      "3 -74.059879 -10.404008  \n",
      "4 -74.037875 -10.418090  \n"
     ]
    }
   ],
   "source": [
    "# 🧹 VALIDACIÓN DE COORDENADAS Y LIMPIEZA DE DATOS\n",
    "print(\"🧹 VALIDACIÓN DE COORDENADAS Y LIMPIEZA DE DATOS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"🔍 ANÁLISIS DE COORDENADAS ANTES DEL FILTRO:\")\n",
    "coords_antes = len(df_poblacion_procesado)\n",
    "print(f\"   • Total de centros poblados: {coords_antes:,}\")\n",
    "print(f\"   • Rango longitud: {df_poblacion_procesado['longitud'].min():.6f} a {df_poblacion_procesado['longitud'].max():.6f}\")\n",
    "print(f\"   • Rango latitud: {df_poblacion_procesado['latitud'].min():.6f} a {df_poblacion_procesado['latitud'].max():.6f}\")\n",
    "\n",
    "# Verificar coordenadas (0, 0)\n",
    "coords_cero = ((df_poblacion_procesado['longitud'] == 0) & (df_poblacion_procesado['latitud'] == 0)).sum()\n",
    "print(f\"   • Coordenadas (0, 0): {coords_cero:,}\")\n",
    "\n",
    "# Verificar coordenadas nulas\n",
    "coords_null_lon = df_poblacion_procesado['longitud'].isnull().sum()\n",
    "coords_null_lat = df_poblacion_procesado['latitud'].isnull().sum()\n",
    "print(f\"   • Longitudes nulas: {coords_null_lon:,}\")\n",
    "print(f\"   • Latitudes nulas: {coords_null_lat:,}\")\n",
    "\n",
    "print(f\"\\n🌍 APLICANDO FILTRO DE COORDENADAS VÁLIDAS PARA PERÚ:\")\n",
    "print(f\"   • Longitud: -81.5° a -68.0° (territorio peruano)\")\n",
    "print(f\"   • Latitud: -18.5° a 0.5° (territorio peruano)\")\n",
    "print(f\"   • Excluyendo coordenadas (0, 0)\")\n",
    "\n",
    "# Filtro para coordenadas válidas en territorio peruano\n",
    "df_poblacion_procesado = df_poblacion_procesado[\n",
    "    (df_poblacion_procesado['longitud'] >= -81.5) & \n",
    "    (df_poblacion_procesado['longitud'] <= -68.0) &\n",
    "    (df_poblacion_procesado['latitud'] >= -18.5) & \n",
    "    (df_poblacion_procesado['latitud'] <= 0.5) &\n",
    "    (df_poblacion_procesado['longitud'] != 0) &\n",
    "    (df_poblacion_procesado['latitud'] != 0) &\n",
    "    (df_poblacion_procesado['longitud'].notna()) &\n",
    "    (df_poblacion_procesado['latitud'].notna())\n",
    "]\n",
    "\n",
    "coords_despues = len(df_poblacion_procesado)\n",
    "coords_eliminados = coords_antes - coords_despues\n",
    "\n",
    "print(f\"\\n✅ RESULTADO DEL FILTRO:\")\n",
    "print(f\"   • Centros poblados válidos: {coords_despues:,}\")\n",
    "print(f\"   • Centros poblados eliminados: {coords_eliminados:,}\")\n",
    "print(f\"   • Porcentaje conservado: {(coords_despues/coords_antes)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n🗺️ RANGO GEOGRÁFICO DESPUÉS DEL FILTRO:\")\n",
    "print(f\"   • Longitud: {df_poblacion_procesado['longitud'].min():.6f} a {df_poblacion_procesado['longitud'].max():.6f}\")\n",
    "print(f\"   • Latitud: {df_poblacion_procesado['latitud'].min():.6f} a {df_poblacion_procesado['latitud'].max():.6f}\")\n",
    "\n",
    "print(f\"\\n🧹 LIMPIEZA Y ESTANDARIZACIÓN DE CAMPOS DE TEXTO:\")\n",
    "\n",
    "# Limpiar campos de texto\n",
    "df_poblacion_procesado['nombre_centro_poblado'] = df_poblacion_procesado['nombre_centro_poblado'].str.strip().str.upper()\n",
    "df_poblacion_procesado['departamento'] = df_poblacion_procesado['departamento'].str.strip().str.upper()\n",
    "df_poblacion_procesado['provincia'] = df_poblacion_procesado['provincia'].str.strip().str.upper()\n",
    "df_poblacion_procesado['distrito'] = df_poblacion_procesado['distrito'].str.strip().str.upper()\n",
    "\n",
    "print(f\"   ✅ Campos de texto estandarizados (mayúsculas, sin espacios extra)\")\n",
    "\n",
    "print(f\"\\n📊 ESTADÍSTICAS FINALES:\")\n",
    "print(f\"   • Departamentos únicos: {df_poblacion_procesado['departamento'].nunique()}\")\n",
    "print(f\"   • Provincias únicas: {df_poblacion_procesado['provincia'].nunique()}\")\n",
    "print(f\"   • Distritos únicos: {df_poblacion_procesado['distrito'].nunique()}\")\n",
    "\n",
    "print(f\"\\n🏴 DISTRIBUCIÓN POR DEPARTAMENTO (Top 10):\")\n",
    "dep_counts = df_poblacion_procesado['departamento'].value_counts().head(10)\n",
    "for i, (dep, count) in enumerate(dep_counts.items(), 1):\n",
    "    porcentaje = (count / len(df_poblacion_procesado)) * 100\n",
    "    print(f\"   {i:2d}. {dep}: {count:,} ({porcentaje:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📋 MUESTRA DEL DATASET LIMPIO:\")\n",
    "print(df_poblacion_procesado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93f00af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 GUARDANDO DATASET FINAL EN CARPETA DATAFINAL\n",
      "============================================================\n",
      "📁 Carpeta DATAFINAL verificada/creada\n",
      "\n",
      "✅ ARCHIVO GUARDADO EXITOSAMENTE:\n",
      "   📄 Archivo: ../DATAFINAL/poblacion_procesado.csv\n",
      "   📊 Registros: 136,587\n",
      "   📋 Columnas: 7\n",
      "   💾 Tamaño: 10.82 MB\n",
      "\n",
      "📋 RESUMEN DEL DATASET PROCESADO PARA HACKATON:\n",
      "🎯 PROPÓSITO: Sistema de Monitoreo y Alerta Temprana Ambiental\n",
      "📊 DATOS DE POBLACIÓN LISTOS PARA:\n",
      "   • Correlación con puntos de monitoreo ambiental\n",
      "   • Análisis de densidad poblacional en zonas de riesgo\n",
      "   • Identificación de centros poblados vulnerables\n",
      "   • Cálculo de población afectada por contaminación\n",
      "   • Alertas tempranas para comunidades\n",
      "\n",
      "🔗 CAMPOS CLAVE PARA TU HACKATON:\n",
      "   🗺️ Geoespaciales: latitud, longitud\n",
      "   🏘️ Identificación: id_centro_poblado, nombre_centro_poblado\n",
      "   📍 Ubicación: departamento, provincia, distrito\n",
      "\n",
      "🏛️ DISTRIBUCIÓN GEOGRÁFICA (Top 5):\n",
      "   1. PUNO: 16,804 (12.3%)\n",
      "   2. CUSCO: 13,496 (9.9%)\n",
      "   3. ANCASH: 10,658 (7.8%)\n",
      "   4. AYACUCHO: 10,081 (7.4%)\n",
      "   5. HUANUCO: 9,193 (6.7%)\n",
      "\n",
      "🌍 COBERTURA GEOGRÁFICA:\n",
      "   • Departamentos: 28\n",
      "   • Provincias: 208\n",
      "   • Distritos: 1790\n",
      "\n",
      "📊 COMPARACIÓN CON OTROS DATASETS:\n",
      "   🏥 Centros de salud: ~7,953 registros\n",
      "   🎓 Instituciones educativas: ~177,871 registros\n",
      "   🏘️ Centros poblados: 136,587 registros\n",
      "\n",
      "🗂️ ARCHIVOS EN DATAFINAL:\n",
      "   1. poblacion_procesado.csv (10.8 MB)\n",
      "   2. salud_procesado.csv (1.5 MB)\n",
      "   3. educacion_procesado.csv (30.4 MB)\n",
      "\n",
      "🚀 DATASETS COMPLETADOS PARA HACKATON:\n",
      "   ✅ Salud: salud_procesado.csv\n",
      "   ✅ Educación: educacion_procesado.csv\n",
      "   ✅ Población: poblacion_procesado.csv\n",
      "\n",
      "🎯 PRÓXIMO PASO: Integrar todos los datasets para análisis conjunto\n",
      "✅ DATASET DE CENTROS POBLADOS COMPLETADO Y LISTO PARA HACKATON\n"
     ]
    }
   ],
   "source": [
    "# 💾 GUARDAR DATASET CENTROS POBLADOS EN CARPETA DATAFINAL\n",
    "print(\"💾 GUARDANDO DATASET FINAL EN CARPETA DATAFINAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import os\n",
    "\n",
    "# Crear carpeta DATAFINAL si no existe\n",
    "datafinal_path = '../DATAFINAL'\n",
    "os.makedirs(datafinal_path, exist_ok=True)\n",
    "print(f\"📁 Carpeta DATAFINAL verificada/creada\")\n",
    "\n",
    "# Guardar dataset procesado\n",
    "archivo_final = os.path.join(datafinal_path, 'poblacion_procesado.csv')\n",
    "\n",
    "try:\n",
    "    df_poblacion_procesado.to_csv(archivo_final, index=False, encoding='utf-8')\n",
    "    print(f\"\\n✅ ARCHIVO GUARDADO EXITOSAMENTE:\")\n",
    "    print(f\"   📄 Archivo: {archivo_final}\")\n",
    "    print(f\"   📊 Registros: {len(df_poblacion_procesado):,}\")\n",
    "    print(f\"   📋 Columnas: {len(df_poblacion_procesado.columns)}\")\n",
    "    \n",
    "    # Verificar tamaño del archivo\n",
    "    size_mb = os.path.getsize(archivo_final) / (1024 * 1024)\n",
    "    print(f\"   💾 Tamaño: {size_mb:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error guardando archivo: {e}\")\n",
    "\n",
    "print(f\"\\n📋 RESUMEN DEL DATASET PROCESADO PARA HACKATON:\")\n",
    "print(f\"🎯 PROPÓSITO: Sistema de Monitoreo y Alerta Temprana Ambiental\")\n",
    "print(f\"📊 DATOS DE POBLACIÓN LISTOS PARA:\")\n",
    "print(f\"   • Correlación con puntos de monitoreo ambiental\")\n",
    "print(f\"   • Análisis de densidad poblacional en zonas de riesgo\")\n",
    "print(f\"   • Identificación de centros poblados vulnerables\")\n",
    "print(f\"   • Cálculo de población afectada por contaminación\")\n",
    "print(f\"   • Alertas tempranas para comunidades\")\n",
    "\n",
    "print(f\"\\n🔗 CAMPOS CLAVE PARA TU HACKATON:\")\n",
    "print(f\"   🗺️ Geoespaciales: latitud, longitud\")\n",
    "print(f\"   🏘️ Identificación: id_centro_poblado, nombre_centro_poblado\")\n",
    "print(f\"   📍 Ubicación: departamento, provincia, distrito\")\n",
    "\n",
    "print(f\"\\n🏛️ DISTRIBUCIÓN GEOGRÁFICA (Top 5):\")\n",
    "top_deptos = df_poblacion_procesado['departamento'].value_counts().head(5)\n",
    "for i, (depto, count) in enumerate(top_deptos.items(), 1):\n",
    "    porcentaje = (count / len(df_poblacion_procesado)) * 100\n",
    "    print(f\"   {i}. {depto}: {count:,} ({porcentaje:.1f}%)\")\n",
    "\n",
    "print(f\"\\n🌍 COBERTURA GEOGRÁFICA:\")\n",
    "print(f\"   • Departamentos: {df_poblacion_procesado['departamento'].nunique()}\")\n",
    "print(f\"   • Provincias: {df_poblacion_procesado['provincia'].nunique()}\")\n",
    "print(f\"   • Distritos: {df_poblacion_procesado['distrito'].nunique()}\")\n",
    "\n",
    "print(f\"\\n📊 COMPARACIÓN CON OTROS DATASETS:\")\n",
    "print(f\"   🏥 Centros de salud: ~7,953 registros\")\n",
    "print(f\"   🎓 Instituciones educativas: ~177,871 registros\") \n",
    "print(f\"   🏘️ Centros poblados: {len(df_poblacion_procesado):,} registros\")\n",
    "\n",
    "print(f\"\\n🗂️ ARCHIVOS EN DATAFINAL:\")\n",
    "datafinal_files = os.listdir(datafinal_path) if os.path.exists(datafinal_path) else []\n",
    "for i, file in enumerate(datafinal_files, 1):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(datafinal_path, file)\n",
    "        file_size = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\"   {i}. {file} ({file_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\n🚀 DATASETS COMPLETADOS PARA HACKATON:\")\n",
    "print(f\"   ✅ Salud: salud_procesado.csv\")\n",
    "print(f\"   ✅ Educación: educacion_procesado.csv\") \n",
    "print(f\"   ✅ Población: poblacion_procesado.csv\")\n",
    "\n",
    "print(f\"\\n🎯 PRÓXIMO PASO: Integrar todos los datasets para análisis conjunto\")\n",
    "print(f\"✅ DATASET DE CENTROS POBLADOS COMPLETADO Y LISTO PARA HACKATON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
